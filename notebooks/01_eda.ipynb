{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E-Commerce Customer Churn Prediction\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Author:** Muhammad Abdullah  \n",
    "**Project:** ML Fundamentals - Customer Churn Prediction\n",
    "\n",
    "---\n",
    "\n",
    "### Objectives:\n",
    "1. Load and understand the dataset\n",
    "2. Analyze data quality (missing values, duplicates)\n",
    "3. Explore feature distributions\n",
    "4. Analyze relationships with target variable\n",
    "5. Identify patterns and insights for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print('Libraries imported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Update the path to your actual dataset location\n",
    "DATA_PATH = project_root / 'data' / 'raw' / 'ecommerce_customer_churn.csv'\n",
    "\n",
    "# Alternative: If using Excel file\n",
    "# DATA_PATH = project_root / 'data' / 'raw' / 'E Commerce Dataset.xlsx'\n",
    "\n",
    "try:\n",
    "    if DATA_PATH.suffix == '.csv':\n",
    "        df = pd.read_csv(DATA_PATH)\n",
    "    else:\n",
    "        df = pd.read_excel(DATA_PATH, sheet_name='E Comm')\n",
    "    print(f'Dataset loaded successfully!')\n",
    "    print(f'Shape: {df.shape[0]} rows, {df.shape[1]} columns')\n",
    "except FileNotFoundError:\n",
    "    print(f'File not found at {DATA_PATH}')\n",
    "    print('Please place your dataset in the data/raw folder')\n",
    "    # Create sample data for demonstration\n",
    "    print('\\nCreating sample data for demonstration...')\n",
    "    np.random.seed(42)\n",
    "    n_samples = 5000\n",
    "    df = pd.DataFrame({\n",
    "        'CustomerID': range(1, n_samples + 1),\n",
    "        'Churn': np.random.choice([0, 1], n_samples, p=[0.83, 0.17]),\n",
    "        'Tenure': np.random.randint(0, 61, n_samples),\n",
    "        'PreferredLoginDevice': np.random.choice(['Mobile Phone', 'Computer', 'Phone'], n_samples),\n",
    "        'CityTier': np.random.choice([1, 2, 3], n_samples),\n",
    "        'WarehouseToHome': np.random.uniform(5, 35, n_samples),\n",
    "        'PreferredPaymentMode': np.random.choice(['Debit Card', 'Credit Card', 'E wallet', 'COD', 'UPI'], n_samples),\n",
    "        'Gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "        'HourSpendOnApp': np.random.uniform(0, 5, n_samples),\n",
    "        'NumberOfDeviceRegistered': np.random.randint(1, 7, n_samples),\n",
    "        'PreferedOrderCat': np.random.choice(['Laptop & Accessory', 'Mobile', 'Fashion', 'Grocery', 'Others'], n_samples),\n",
    "        'SatisfactionScore': np.random.randint(1, 6, n_samples),\n",
    "        'MaritalStatus': np.random.choice(['Single', 'Married', 'Divorced'], n_samples),\n",
    "        'NumberOfAddress': np.random.randint(1, 11, n_samples),\n",
    "        'Complain': np.random.choice([0, 1], n_samples, p=[0.72, 0.28]),\n",
    "        'OrderAmountHikeFromlastYear': np.random.uniform(11, 26, n_samples),\n",
    "        'CouponUsed': np.random.randint(0, 16, n_samples),\n",
    "        'OrderCount': np.random.randint(1, 16, n_samples),\n",
    "        'DaySinceLastOrder': np.random.randint(0, 46, n_samples),\n",
    "        'CashbackAmount': np.random.uniform(0, 325, n_samples)\n",
    "    })\n",
    "    print(f'Sample data created: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic info\n",
    "print('Dataset Info:')\n",
    "print('=' * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing,\n",
    "    'Missing %': missing_pct\n",
    "}).sort_values('Missing %', ascending=False)\n",
    "\n",
    "print('Missing Values Analysis:')\n",
    "print('=' * 50)\n",
    "print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "if missing_df['Missing Count'].sum() == 0:\n",
    "    print('No missing values found!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "if missing_df['Missing Count'].sum() > 0:\n",
    "    fig = px.bar(\n",
    "        missing_df[missing_df['Missing Count'] > 0].reset_index(),\n",
    "        x='index', y='Missing %',\n",
    "        title='Missing Values by Feature',\n",
    "        labels={'index': 'Feature', 'Missing %': 'Percentage Missing'}\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f'Duplicate rows: {duplicates} ({duplicates/len(df)*100:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "target_col = 'Churn'\n",
    "\n",
    "print('Target Variable Distribution:')\n",
    "print('=' * 50)\n",
    "print(df[target_col].value_counts())\n",
    "print(f'\\nChurn Rate: {df[target_col].mean()*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "fig = make_subplots(rows=1, cols=2, specs=[[{'type':'xy'}, {'type':'domain'}]])\n",
    "\n",
    "# Bar chart\n",
    "counts = df[target_col].value_counts()\n",
    "fig.add_trace(\n",
    "    go.Bar(x=['No Churn', 'Churn'], y=counts.values, marker_color=['#2ecc71', '#e74c3c']),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Pie chart\n",
    "fig.add_trace(\n",
    "    go.Pie(labels=['No Churn', 'Churn'], values=counts.values, \n",
    "           marker_colors=['#2ecc71', '#e74c3c']),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_layout(title='Churn Distribution', showlegend=False, height=400)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify feature types\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove target and ID from numerical\n",
    "if 'CustomerID' in numerical_cols:\n",
    "    numerical_cols.remove('CustomerID')\n",
    "if target_col in numerical_cols:\n",
    "    numerical_cols.remove(target_col)\n",
    "\n",
    "print(f'Numerical features ({len(numerical_cols)}): {numerical_cols}')\n",
    "print(f'\\nCategorical features ({len(categorical_cols)}): {categorical_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features distribution\n",
    "n_cols = 3\n",
    "n_rows = (len(numerical_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols):\n",
    "    ax = axes[idx]\n",
    "    df[col].hist(bins=30, ax=ax, edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(f'{col}', fontsize=12)\n",
    "    ax.set_xlabel('')\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(len(numerical_cols), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'figures' / 'numerical_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features distribution\n",
    "n_cols = 2\n",
    "n_rows = (len(categorical_cols) + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(categorical_cols):\n",
    "    ax = axes[idx]\n",
    "    df[col].value_counts().plot(kind='bar', ax=ax, edgecolor='black', alpha=0.7)\n",
    "    ax.set_title(f'{col}', fontsize=12)\n",
    "    ax.set_xlabel('')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Hide empty subplots\n",
    "for idx in range(len(categorical_cols), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'figures' / 'categorical_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature vs Target Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features vs Churn\n",
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(numerical_cols[:12]):\n",
    "    ax = axes[idx]\n",
    "    df.boxplot(column=col, by=target_col, ax=ax)\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('Churn')\n",
    "\n",
    "plt.suptitle('Numerical Features by Churn Status', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(project_root / 'reports' / 'figures' / 'numerical_vs_churn.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features vs Churn\n",
    "for col in categorical_cols:\n",
    "    fig = px.histogram(\n",
    "        df, x=col, color=target_col.astype(str) if df[target_col].dtype != 'object' else target_col,\n",
    "        barmode='group',\n",
    "        title=f'{col} by Churn Status',\n",
    "        color_discrete_map={'0': '#2ecc71', '1': '#e74c3c'}\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn rate by categorical features\n",
    "for col in categorical_cols:\n",
    "    churn_rate = df.groupby(col)[target_col].mean() * 100\n",
    "    fig = px.bar(\n",
    "        x=churn_rate.index, y=churn_rate.values,\n",
    "        title=f'Churn Rate by {col}',\n",
    "        labels={'x': col, 'y': 'Churn Rate (%)'},\n",
    "        color=churn_rate.values,\n",
    "        color_continuous_scale='RdYlGn_r'\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for numerical features\n",
    "corr_cols = numerical_cols + [target_col]\n",
    "corr_matrix = df[corr_cols].corr()\n",
    "\n",
    "fig = px.imshow(\n",
    "    corr_matrix,\n",
    "    text_auto='.2f',\n",
    "    aspect='auto',\n",
    "    title='Correlation Matrix',\n",
    "    color_continuous_scale='RdBu_r'\n",
    ")\n",
    "fig.update_layout(width=900, height=700)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target\n",
    "target_corr = corr_matrix[target_col].drop(target_col).sort_values(ascending=False)\n",
    "\n",
    "fig = px.bar(\n",
    "    x=target_corr.values, y=target_corr.index,\n",
    "    orientation='h',\n",
    "    title='Correlation with Churn',\n",
    "    labels={'x': 'Correlation', 'y': 'Feature'},\n",
    "    color=target_corr.values,\n",
    "    color_continuous_scale='RdBu_r'\n",
    ")\n",
    "fig.update_layout(height=500)\n",
    "fig.show()\n",
    "\n",
    "print('Top positive correlations with Churn:')\n",
    "print(target_corr.head())\n",
    "print('\\nTop negative correlations with Churn:')\n",
    "print(target_corr.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('='*60)\n",
    "print('KEY INSIGHTS FROM EDA')\n",
    "print('='*60)\n",
    "\n",
    "print(f'''\n",
    "1. DATASET OVERVIEW:\n",
    "   - Total samples: {len(df)}\n",
    "   - Features: {len(df.columns) - 2} (excluding ID and target)\n",
    "   - Churn rate: {df[target_col].mean()*100:.2f}%\n",
    "\n",
    "2. DATA QUALITY:\n",
    "   - Missing values: {df.isnull().sum().sum()}\n",
    "   - Duplicates: {df.duplicated().sum()}\n",
    "   - Class imbalance: {'Yes - minority class needs handling' if df[target_col].mean() < 0.3 else 'Moderate'}\n",
    "\n",
    "3. TOP CHURN INDICATORS (by correlation):\n",
    "   {target_corr.head(3).to_string()}\n",
    "\n",
    "4. FEATURE ENGINEERING OPPORTUNITIES:\n",
    "   - Create tenure-based segments\n",
    "   - Calculate engagement scores\n",
    "   - Build recency/frequency metrics\n",
    "   - Create satisfaction risk flags\n",
    "\n",
    "5. MODELING RECOMMENDATIONS:\n",
    "   - Handle class imbalance (SMOTE/class weights)\n",
    "   - Use ensemble methods (XGBoost, LightGBM)\n",
    "   - Perform hyperparameter tuning\n",
    "   - Apply cross-validation\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for modeling\n",
    "df.to_parquet(project_root / 'data' / 'processed' / 'eda_data.parquet', index=False)\n",
    "print('Data saved for modeling!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
